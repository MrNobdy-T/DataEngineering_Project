{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0102b60-a5a3-4430-81fd-ad0eebbdb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class RedditDeepScraper:\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) ResearchBot/2.0\"})\n",
    "\n",
    "    def fetch_all_comments(self, subreddit, post_id):\n",
    "        url = f\"https://www.reddit.com/r/{subreddit}/comments/{post_id}.json\"\n",
    "        response = self.session.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        \n",
    "        # Reddit JSON structure: [PostObject, CommentObject]\n",
    "        # We target the 'children' in the CommentObject\n",
    "        comment_forest = response.json()[1]['data']['children']\n",
    "        \n",
    "        flat_comments = []\n",
    "        self._parse_tree(comment_forest, flat_comments)\n",
    "        return flat_comments\n",
    "\n",
    "    def _parse_tree(self, children, result_list):\n",
    "        \"\"\"Recursively walks the comment tree to flatten it.\"\"\"\n",
    "        for child in children:\n",
    "            if child['kind'] == 't1': # t1 = Comment\n",
    "                data = child['data']\n",
    "                result_list.append({\n",
    "                    \"comment_id\": data.get('id'),\n",
    "                    \"parent_id\": data.get('parent_id'),\n",
    "                    \"author\": data.get('author'),\n",
    "                    \"body\": data.get('body'),\n",
    "                    \"score\": data.get('score'),\n",
    "                    \"created_utc\": datetime.fromtimestamp(data.get('created_utc')) if data.get('created_utc') else None\n",
    "                })\n",
    "                \n",
    "                # Check for replies (nested tree)\n",
    "                replies = data.get('replies')\n",
    "                if replies and isinstance(replies, dict):\n",
    "                    inner_children = replies.get('data', {}).get('children', [])\n",
    "                    self._parse_tree(inner_children, result_list)\n",
    "\n",
    "scraper = RedditDeepScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9072a04-ae53-4326-af78-02e0d3a05016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep scraping: First Time Audi Owner...\n",
      "Deep scraping: Talk me out of it: 2016 A5 Sportback 3.0T (B8.5) with 80k km...\n",
      "\n",
      "Done! Captured 15 total rows (posts + comments) across 2 posts.\n"
     ]
    }
   ],
   "source": [
    "SUBREDDIT = \"Audi\"\n",
    "QUERY = \"bmw\"\n",
    "POST_LIMIT = 100\n",
    "\n",
    "search_url = f\"https://www.reddit.com/r/{SUBREDDIT}/search.json\"\n",
    "search_params = {\"q\": QUERY, \"restrict_sr\": \"on\", \"sort\": \"hot\", \"limit\": POST_LIMIT}\n",
    "search_res = scraper.session.get(search_url, params=search_params).json()\n",
    "posts = [p['data'] for p in search_res['data']['children']]\n",
    "\n",
    "all_data_rows = []\n",
    "\n",
    "for post in posts:\n",
    "    p_id = post['id']\n",
    "    p_title = post['title']\n",
    "    print(f\"Deep scraping: {p_title[:60]}...\")\n",
    "    \n",
    "    all_data_rows.append({\n",
    "        \"type\": \"post\",\n",
    "        \"post_id\": p_id,\n",
    "        \"post_title\": p_title,\n",
    "        \"comment_id\": None,\n",
    "        \"author\": post.get('author'),\n",
    "        \"body\": post.get('selftext', ''),\n",
    "        \"score\": post.get('score'),\n",
    "        \"created_utc\": post.get('created_utc')\n",
    "    })\n",
    "    \n",
    "    # 3. Get all comments in the tree\n",
    "    comments = scraper.fetch_all_comments(SUBREDDIT, p_id)\n",
    "    \n",
    "    for c in comments:\n",
    "        c['type'] = \"comment\"\n",
    "        c['post_id'] = p_id\n",
    "        c['post_title'] = p_title\n",
    "        all_data_rows.append(c)\n",
    "    \n",
    "    time.sleep(5) \n",
    "\n",
    "# 4. Create DataFrame\n",
    "df = pd.DataFrame(all_data_rows)\n",
    "print(f\"\\nDone! Captured {len(df)} total rows (posts + comments) across {len(posts)} posts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89663c18-f6b2-450a-950d-23cd1fab1ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported 15 entries.\n",
      "File location: E:\\Fachhochschule\\Master\\1. Semester\\Data Engineering Techniques\\Projekt\\DataEngineering_Project\\data\\Audi_bmw_100posts_full.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post</td>\n",
       "      <td>1q4ia7n</td>\n",
       "      <td>Colgray21</td>\n",
       "      <td>Traded up from a BMW 535i to this 2024 Q5 and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>ThatOtherOmar</td>\n",
       "      <td>Iâ€™m considering trading my 2007 BMW E92 328i f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>Beemeristic</td>\n",
       "      <td>Easy, if you don't have maintenance/repair mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>PurpleSlightlyRed</td>\n",
       "      <td>Previous owner spent more money on the fake RS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>alexberbo</td>\n",
       "      <td>Skip, those mods are terrible, fake RS bumper ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>96JY</td>\n",
       "      <td>The seats are a shade of poop.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>No-Room-3886</td>\n",
       "      <td>I didnt know these existed. Previous dudes don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>xRaffaell</td>\n",
       "      <td>Probably fake kms or not mentained properly du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>Super-Total-661</td>\n",
       "      <td>You dont need us to talk you out of it or into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comment</td>\n",
       "      <td>1q3wjtk</td>\n",
       "      <td>Important-Ad-6754</td>\n",
       "      <td>My guess is your Lebanese ðŸ‘Œ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  post_id             author  \\\n",
       "0     post  1q4ia7n          Colgray21   \n",
       "1     post  1q3wjtk      ThatOtherOmar   \n",
       "2  comment  1q3wjtk        Beemeristic   \n",
       "3  comment  1q3wjtk  PurpleSlightlyRed   \n",
       "4  comment  1q3wjtk          alexberbo   \n",
       "5  comment  1q3wjtk               96JY   \n",
       "6  comment  1q3wjtk       No-Room-3886   \n",
       "7  comment  1q3wjtk          xRaffaell   \n",
       "8  comment  1q3wjtk    Super-Total-661   \n",
       "9  comment  1q3wjtk  Important-Ad-6754   \n",
       "\n",
       "                                                body  \n",
       "0  Traded up from a BMW 535i to this 2024 Q5 and ...  \n",
       "1  Iâ€™m considering trading my 2007 BMW E92 328i f...  \n",
       "2  Easy, if you don't have maintenance/repair mon...  \n",
       "3  Previous owner spent more money on the fake RS...  \n",
       "4  Skip, those mods are terrible, fake RS bumper ...  \n",
       "5                     The seats are a shade of poop.  \n",
       "6  I didnt know these existed. Previous dudes don...  \n",
       "7  Probably fake kms or not mentained properly du...  \n",
       "8  You dont need us to talk you out of it or into...  \n",
       "9                        My guess is your Lebanese ðŸ‘Œ  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "target_dir = Path(\"..\") / \"data\"\n",
    "filename = f\"{SUBREDDIT}_{QUERY}_100posts_full.csv\"\n",
    "file_path = target_dir / filename\n",
    "\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3. Final Export\n",
    "if not df.empty:\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Successfully exported {len(df)} entries.\")\n",
    "    print(f\"File location: {file_path.resolve()}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty. No file was saved.\")\n",
    "\n",
    "df[['type', 'post_id', 'author', 'body']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9d1b5-ecb9-4645-af72-ec24b11d25d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
